{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d47b405",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import csv\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "640aac51",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(r'train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "610a5895",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>relation</th>\n",
       "      <th>head</th>\n",
       "      <th>head_type</th>\n",
       "      <th>head_offset</th>\n",
       "      <th>tail</th>\n",
       "      <th>tail_type</th>\n",
       "      <th>tail_offset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>《逐风行》是百度文学旗下纵横中文网签约作家清水秋风创作的一部东方玄幻小说，小说已于2014-...</td>\n",
       "      <td>连载网站</td>\n",
       "      <td>逐风行</td>\n",
       "      <td>网络小说</td>\n",
       "      <td>1</td>\n",
       "      <td>纵横中文网</td>\n",
       "      <td>网站</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>谢万松，字树人，湖北省武汉市人，武汉钢铁集团公司联合焦化公司退体职工，生于1940年</td>\n",
       "      <td>出生地</td>\n",
       "      <td>谢万松</td>\n",
       "      <td>人物</td>\n",
       "      <td>0</td>\n",
       "      <td>湖北省武汉市</td>\n",
       "      <td>地点</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>《娘家的故事第二部》是张玲执导，林在培、何赛飞等主演的电视剧</td>\n",
       "      <td>导演</td>\n",
       "      <td>娘家的故事第二部</td>\n",
       "      <td>影视作品</td>\n",
       "      <td>1</td>\n",
       "      <td>张玲</td>\n",
       "      <td>人物</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>九玄珠是在纵横中文网连载的一部小说，作者是龙马</td>\n",
       "      <td>连载网站</td>\n",
       "      <td>九玄珠</td>\n",
       "      <td>网络小说</td>\n",
       "      <td>0</td>\n",
       "      <td>纵横中文网</td>\n",
       "      <td>网站</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>《下半生留住你一直相爱》是商人醉猫写的网络小说连载于17k小说网</td>\n",
       "      <td>连载网站</td>\n",
       "      <td>下半生留住你一直相爱</td>\n",
       "      <td>网络小说</td>\n",
       "      <td>1</td>\n",
       "      <td>17k小说网</td>\n",
       "      <td>网站</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>演说上中学时，虽然没出过县城没坐过汽车，但我已从课本上知道英国首都伦敦有个海德公园，那里有个...</td>\n",
       "      <td>所在城市</td>\n",
       "      <td>海德公园</td>\n",
       "      <td>景点</td>\n",
       "      <td>37</td>\n",
       "      <td>伦敦</td>\n",
       "      <td>城市</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>项目建设借鉴伦敦皇家园林——海德公园的营建思路，将城市生活与自然生态无缝对接，创造出优雅、国...</td>\n",
       "      <td>所在城市</td>\n",
       "      <td>海德公园</td>\n",
       "      <td>景点</td>\n",
       "      <td>14</td>\n",
       "      <td>伦敦</td>\n",
       "      <td>城市</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>梁启超故居，有多处，分别位于北京、天津、新会等地</td>\n",
       "      <td>所在城市</td>\n",
       "      <td>梁启超故居</td>\n",
       "      <td>景点</td>\n",
       "      <td>0</td>\n",
       "      <td>天津</td>\n",
       "      <td>城市</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>2000年，上海城隍庙修复一期工程基本结束，并于同年11月14日举行住持升座仪式，上海市道教...</td>\n",
       "      <td>所在城市</td>\n",
       "      <td>城隍庙</td>\n",
       "      <td>景点</td>\n",
       "      <td>8</td>\n",
       "      <td>上海市</td>\n",
       "      <td>城市</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>从2004年起，每年的六月初，在美泉宫的花园，维也纳的爱乐乐团都举行一场露天的晚场音乐会，这...</td>\n",
       "      <td>所在城市</td>\n",
       "      <td>美泉宫</td>\n",
       "      <td>景点</td>\n",
       "      <td>16</td>\n",
       "      <td>维也纳</td>\n",
       "      <td>城市</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence relation        head  \\\n",
       "0     《逐风行》是百度文学旗下纵横中文网签约作家清水秋风创作的一部东方玄幻小说，小说已于2014-...     连载网站         逐风行   \n",
       "1            谢万松，字树人，湖北省武汉市人，武汉钢铁集团公司联合焦化公司退体职工，生于1940年      出生地         谢万松   \n",
       "2                        《娘家的故事第二部》是张玲执导，林在培、何赛飞等主演的电视剧       导演    娘家的故事第二部   \n",
       "3                               九玄珠是在纵横中文网连载的一部小说，作者是龙马     连载网站         九玄珠   \n",
       "4                      《下半生留住你一直相爱》是商人醉猫写的网络小说连载于17k小说网     连载网站  下半生留住你一直相爱   \n",
       "...                                                 ...      ...         ...   \n",
       "3995  演说上中学时，虽然没出过县城没坐过汽车，但我已从课本上知道英国首都伦敦有个海德公园，那里有个...     所在城市        海德公园   \n",
       "3996  项目建设借鉴伦敦皇家园林——海德公园的营建思路，将城市生活与自然生态无缝对接，创造出优雅、国...     所在城市        海德公园   \n",
       "3997                           梁启超故居，有多处，分别位于北京、天津、新会等地     所在城市       梁启超故居   \n",
       "3998  2000年，上海城隍庙修复一期工程基本结束，并于同年11月14日举行住持升座仪式，上海市道教...     所在城市         城隍庙   \n",
       "3999  从2004年起，每年的六月初，在美泉宫的花园，维也纳的爱乐乐团都举行一场露天的晚场音乐会，这...     所在城市         美泉宫   \n",
       "\n",
       "     head_type  head_offset    tail tail_type  tail_offset  \n",
       "0         网络小说            1   纵横中文网        网站           12  \n",
       "1           人物            0  湖北省武汉市        地点            8  \n",
       "2         影视作品            1      张玲        人物           11  \n",
       "3         网络小说            0   纵横中文网        网站            5  \n",
       "4         网络小说            1  17k小说网        网站           26  \n",
       "...        ...          ...     ...       ...          ...  \n",
       "3995        景点           37      伦敦        城市           33  \n",
       "3996        景点           14      伦敦        城市            6  \n",
       "3997        景点            0      天津        城市           17  \n",
       "3998        景点            8     上海市        城市           41  \n",
       "3999        景点           16     维也纳        城市           23  \n",
       "\n",
       "[4000 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55df8a78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>relation</th>\n",
       "      <th>head</th>\n",
       "      <th>head_type</th>\n",
       "      <th>head_offset</th>\n",
       "      <th>tail</th>\n",
       "      <th>tail_type</th>\n",
       "      <th>tail_offset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>孔正锡，导演，2005年以一部温馨的爱情电影《长腿叔叔》敲开电影界大门</td>\n",
       "      <td>导演</td>\n",
       "      <td>长腿叔叔</td>\n",
       "      <td>影视作品</td>\n",
       "      <td>23</td>\n",
       "      <td>孔正锡</td>\n",
       "      <td>人物</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>《我家有喜2》（又名《开门见喜》）是由丁仰国导演执导，张佳编剧，海陆、高梓淇、万茜、李佳航、...</td>\n",
       "      <td>导演</td>\n",
       "      <td>我家有喜</td>\n",
       "      <td>影视作品</td>\n",
       "      <td>1</td>\n",
       "      <td>丁仰国</td>\n",
       "      <td>人物</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>解福印导演还表示这次虽然选用新人做主演，但对他们的表现绝对有信心，“跟以往的功夫片不同，《功...</td>\n",
       "      <td>导演</td>\n",
       "      <td>功夫世家</td>\n",
       "      <td>影视作品</td>\n",
       "      <td>45</td>\n",
       "      <td>解福印</td>\n",
       "      <td>人物</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>《疯狂艳唇》是佐佐木浩久执导的一部恐怖剧情电影，本电影由新人三轮瞳映画初主演</td>\n",
       "      <td>导演</td>\n",
       "      <td>疯狂艳唇</td>\n",
       "      <td>影视作品</td>\n",
       "      <td>1</td>\n",
       "      <td>佐佐木浩久</td>\n",
       "      <td>人物</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>步入二十一世纪，天愿大介似乎又对导筒发生了兴趣，陆续推出了几部电影，《世界上最美丽的夜晚》是...</td>\n",
       "      <td>导演</td>\n",
       "      <td>世界上最美丽的夜晚</td>\n",
       "      <td>影视作品</td>\n",
       "      <td>35</td>\n",
       "      <td>天愿大介</td>\n",
       "      <td>人物</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>建国后，南京市人民政府于1951年将莫愁湖列为“第一区人民公园”</td>\n",
       "      <td>所在城市</td>\n",
       "      <td>莫愁湖</td>\n",
       "      <td>景点</td>\n",
       "      <td>18</td>\n",
       "      <td>南京</td>\n",
       "      <td>城市</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>重庆中央公园是继纽约·中央公园、伦敦·海德公园之后的世界第三大城市中央公园，也是亚洲最大的城...</td>\n",
       "      <td>所在城市</td>\n",
       "      <td>海德公园</td>\n",
       "      <td>景点</td>\n",
       "      <td>19</td>\n",
       "      <td>伦敦</td>\n",
       "      <td>城市</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>明孝陵坐落在南京市紫金山南麓独龙阜玩珠峰下，东毗中山陵，南临梅花山，是南京最大的帝王陵墓，亦...</td>\n",
       "      <td>所在城市</td>\n",
       "      <td>中山陵</td>\n",
       "      <td>景点</td>\n",
       "      <td>24</td>\n",
       "      <td>南京</td>\n",
       "      <td>城市</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>2000年伊始，天津市政府对马场道进行大规模的整修，作为当年为民办十件实事之一</td>\n",
       "      <td>所在城市</td>\n",
       "      <td>马场道</td>\n",
       "      <td>景点</td>\n",
       "      <td>14</td>\n",
       "      <td>天津市</td>\n",
       "      <td>城市</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>世纪公园是上海内环线中心区域内最大的富有自然特征的生态型城市公园</td>\n",
       "      <td>所在城市</td>\n",
       "      <td>世纪公园</td>\n",
       "      <td>景点</td>\n",
       "      <td>0</td>\n",
       "      <td>上海</td>\n",
       "      <td>城市</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sentence relation       head  \\\n",
       "0                  孔正锡，导演，2005年以一部温馨的爱情电影《长腿叔叔》敲开电影界大门       导演       长腿叔叔   \n",
       "1    《我家有喜2》（又名《开门见喜》）是由丁仰国导演执导，张佳编剧，海陆、高梓淇、万茜、李佳航、...       导演       我家有喜   \n",
       "2    解福印导演还表示这次虽然选用新人做主演，但对他们的表现绝对有信心，“跟以往的功夫片不同，《功...       导演       功夫世家   \n",
       "3               《疯狂艳唇》是佐佐木浩久执导的一部恐怖剧情电影，本电影由新人三轮瞳映画初主演       导演       疯狂艳唇   \n",
       "4    步入二十一世纪，天愿大介似乎又对导筒发生了兴趣，陆续推出了几部电影，《世界上最美丽的夜晚》是...       导演  世界上最美丽的夜晚   \n",
       "..                                                 ...      ...        ...   \n",
       "995                   建国后，南京市人民政府于1951年将莫愁湖列为“第一区人民公园”     所在城市        莫愁湖   \n",
       "996  重庆中央公园是继纽约·中央公园、伦敦·海德公园之后的世界第三大城市中央公园，也是亚洲最大的城...     所在城市       海德公园   \n",
       "997  明孝陵坐落在南京市紫金山南麓独龙阜玩珠峰下，东毗中山陵，南临梅花山，是南京最大的帝王陵墓，亦...     所在城市        中山陵   \n",
       "998            2000年伊始，天津市政府对马场道进行大规模的整修，作为当年为民办十件实事之一     所在城市        马场道   \n",
       "999                   世纪公园是上海内环线中心区域内最大的富有自然特征的生态型城市公园     所在城市       世纪公园   \n",
       "\n",
       "    head_type  head_offset   tail tail_type  tail_offset  \n",
       "0        影视作品           23    孔正锡        人物            0  \n",
       "1        影视作品            1    丁仰国        人物           19  \n",
       "2        影视作品           45    解福印        人物            0  \n",
       "3        影视作品            1  佐佐木浩久        人物            7  \n",
       "4        影视作品           35   天愿大介        人物            8  \n",
       "..        ...          ...    ...       ...          ...  \n",
       "995        景点           18     南京        城市            4  \n",
       "996        景点           19     伦敦        城市           16  \n",
       "997        景点           24     南京        城市            6  \n",
       "998        景点           14    天津市        城市            8  \n",
       "999        景点            0     上海        城市            5  \n",
       "\n",
       "[1000 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv(r'test.csv')\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04f416be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#加载csv\n",
    "def load_csv(file):\n",
    "    data_list = []\n",
    "\n",
    "    with codecs.open(filename=file,encoding='utf-8') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for line in reader:\n",
    "            data = list(line.values())\n",
    "            data_list.append(data)\n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ab49ef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['《逐风行》是百度文学旗下纵横中文网签约作家清水秋风创作的一部东方玄幻小说，小说已于2014-04-28正式发布',\n",
       "  '连载网站',\n",
       "  '逐风行',\n",
       "  '网络小说',\n",
       "  '1',\n",
       "  '纵横中文网',\n",
       "  '网站',\n",
       "  '12'],\n",
       " ['谢万松，字树人，湖北省武汉市人，武汉钢铁集团公司联合焦化公司退体职工，生于1940年',\n",
       "  '出生地',\n",
       "  '谢万松',\n",
       "  '人物',\n",
       "  '0',\n",
       "  '湖北省武汉市',\n",
       "  '地点',\n",
       "  '8'],\n",
       " ['《娘家的故事第二部》是张玲执导，林在培、何赛飞等主演的电视剧',\n",
       "  '导演',\n",
       "  '娘家的故事第二部',\n",
       "  '影视作品',\n",
       "  '1',\n",
       "  '张玲',\n",
       "  '人物',\n",
       "  '11'],\n",
       " ['九玄珠是在纵横中文网连载的一部小说，作者是龙马', '连载网站', '九玄珠', '网络小说', '0', '纵横中文网', '网站', '5'],\n",
       " ['《下半生留住你一直相爱》是商人醉猫写的网络小说连载于17k小说网',\n",
       "  '连载网站',\n",
       "  '下半生留住你一直相爱',\n",
       "  '网络小说',\n",
       "  '1',\n",
       "  '17k小说网',\n",
       "  '网站',\n",
       "  '26']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw_data = load_csv(r'train.csv')\n",
    "test_raw_data = load_csv(r'test.csv')\n",
    "type(train_raw_data)\n",
    "train_raw_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a3c46d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#获取训练接和数据集各自的关系集合\n",
    "train_relation = [] # 训练集中的所有关系\n",
    "test_relation = [] # 测试集中的所有关系\n",
    "for data in train_raw_data:\n",
    "    train_relation.append(data[1])\n",
    "for data in test_raw_data:\n",
    "    test_relation.append(data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e790652c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['连载网站', '出生地', '导演', '连载网站', '连载网站', '国籍', '国籍', '连载网站', '毕业院校', '导演']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_relation[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e236336b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['导演', '导演', '导演', '导演', '导演', '导演', '导演', '导演', '导演', '导演']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_relation[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "0929cc10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['《逐风行》是百度文学旗下纵横中文网签约作家清水秋风创作的一部东方玄幻小说，小说已于2014-04-28正式发布',\n",
       "  '连载网站',\n",
       "  '逐风行',\n",
       "  '网络小说',\n",
       "  '1',\n",
       "  '纵横中文网',\n",
       "  '网站',\n",
       "  '12',\n",
       "  ['《',\n",
       "   '网络小说',\n",
       "   '》',\n",
       "   '是',\n",
       "   '百度',\n",
       "   '文学',\n",
       "   '旗下',\n",
       "   '网站',\n",
       "   '签约',\n",
       "   '作家',\n",
       "   '清水',\n",
       "   '秋风',\n",
       "   '创作',\n",
       "   '的',\n",
       "   '一部',\n",
       "   '东方',\n",
       "   '玄幻',\n",
       "   '小说',\n",
       "   '，',\n",
       "   '小说',\n",
       "   '已于',\n",
       "   '2014',\n",
       "   '-',\n",
       "   '04',\n",
       "   '-',\n",
       "   '28',\n",
       "   '正式',\n",
       "   '发布'],\n",
       "  [1, 7]]]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw_data[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ce481c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "cf632f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#句子分词\n",
    "def split_sentences(raw_data):\n",
    "    new_data_list = []\n",
    "    jieba.add_word('HEAD')\n",
    "    jieba.add_word('TAIL')\n",
    "    for data in raw_data:\n",
    "        head, tail = data[3], data[6]\n",
    "        new_sentence = data[0].replace(data[2], 'HEAD', 1) # 替换句子中的实体关键词\n",
    "        new_sentence = new_sentence.replace(data[5], 'TAIL', 1)\n",
    "        \n",
    "        new_sentence = jieba.lcut(new_sentence)\n",
    "        head_pos, tail_pos = new_sentence.index('HEAD'), new_sentence.index('TAIL')\n",
    "        \n",
    "        new_sentence[head_pos] = head \n",
    "        new_sentence[tail_pos] = tail\n",
    "        data.append(new_sentence)\n",
    "        data.append([head_pos, tail_pos])\n",
    "        \n",
    "        new_data_list.append(data)\n",
    "    return new_data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e34d6b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw_data = split_sentences(train_raw_data)\n",
    "test_raw_data = split_sentences(test_raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "7180d822",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['《逐风行》是百度文学旗下纵横中文网签约作家清水秋风创作的一部东方玄幻小说，小说已于2014-04-28正式发布',\n",
       " '连载网站',\n",
       " '逐风行',\n",
       " '网络小说',\n",
       " '1',\n",
       " '纵横中文网',\n",
       " '网站',\n",
       " '12',\n",
       " ['《',\n",
       "  '网络小说',\n",
       "  '》',\n",
       "  '是',\n",
       "  '百度',\n",
       "  '文学',\n",
       "  '旗下',\n",
       "  '网站',\n",
       "  '签约',\n",
       "  '作家',\n",
       "  '清水',\n",
       "  '秋风',\n",
       "  '创作',\n",
       "  '的',\n",
       "  '一部',\n",
       "  '东方',\n",
       "  '玄幻',\n",
       "  '小说',\n",
       "  '，',\n",
       "  '小说',\n",
       "  '已于',\n",
       "  '2014',\n",
       "  '-',\n",
       "  '04',\n",
       "  '-',\n",
       "  '28',\n",
       "  '正式',\n",
       "  '发布'],\n",
       " [1, 7],\n",
       " ['《',\n",
       "  '网络小说',\n",
       "  '》',\n",
       "  '是',\n",
       "  '百度',\n",
       "  '文学',\n",
       "  '旗下',\n",
       "  '网站',\n",
       "  '签约',\n",
       "  '作家',\n",
       "  '清水',\n",
       "  '秋风',\n",
       "  '创作',\n",
       "  '的',\n",
       "  '一部',\n",
       "  '东方',\n",
       "  '玄幻',\n",
       "  '小说',\n",
       "  '，',\n",
       "  '小说',\n",
       "  '已于',\n",
       "  '2014',\n",
       "  '-',\n",
       "  '04',\n",
       "  '-',\n",
       "  '28',\n",
       "  '正式',\n",
       "  '发布'],\n",
       " [1, 7]]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "19e5151e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['《',\n",
       " '网络小说',\n",
       " '》',\n",
       " '是',\n",
       " '百度',\n",
       " '文学',\n",
       " '旗下',\n",
       " '网站',\n",
       " '签约',\n",
       " '作家',\n",
       " '清水',\n",
       " '秋风',\n",
       " '创作',\n",
       " '的',\n",
       " '一部',\n",
       " '东方',\n",
       " '玄幻',\n",
       " '小说',\n",
       " '，',\n",
       " '小说',\n",
       " '已于',\n",
       " '2014',\n",
       " '-',\n",
       " '04',\n",
       " '-',\n",
       " '28',\n",
       " '正式',\n",
       " '发布']"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw_data[0][-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "938f08de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.vocab import build_vocab_from_iterator # 创建词表工具"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "7f44bc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yield_tokens(raw_data):\n",
    "    for data in raw_data:\n",
    "        yield data[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "6302c660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用训练数据集构建单词表\n",
    "vocab = build_vocab_from_iterator(yield_tokens(train_raw_data), specials=[\"<pad>\", \"<unk>\"], min_freq=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "08576823",
   "metadata": {},
   "outputs": [],
   "source": [
    " vocab.set_default_index(vocab['<unk>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "43ea9f1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6618"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "2f11c771",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = list(vocab.get_stoi().values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "8cae14fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.get_stoi()['<unk>']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d41ab38",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "dd549fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#获取位置编码：\n",
    "def get_pos_feature(sent_len, entity_pos, entity_len = 1, pos_limit = 50):\n",
    "    left = list(range(-entity_pos, 0))\n",
    "    middle = [0] * entity_len\n",
    "    right = list(range(1, sent_len - entity_pos - entity_len + 1))\n",
    "    pos = left + middle + right\n",
    "    for i, p in enumerate(pos):\n",
    "        if p > pos_limit:\n",
    "            pos[i] = pos_limit\n",
    "        if p < -pos_limit:\n",
    "            pos[i] = -pos_limit\n",
    "    \n",
    "    pos = [p + pos_limit + 1 for p in pos]\n",
    "    return pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "e2ec65cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_data(raw_data, vocab):\n",
    "    sents = []\n",
    "    head_pos = []\n",
    "    tail_pos = []\n",
    "    \n",
    "    for data in raw_data:\n",
    "        \n",
    "        \n",
    "        #sent = [vocab.get_stoi()[w] for w in data[-2]]\n",
    "        sent = []\n",
    "        for w in data[-2]: # 迭代取出该句的所有词\n",
    "            if w in vocab: # 判断该词是否在词表中\n",
    "                sent.append(vocab.get_stoi()[w]) # 有，则将居中的单词转为id\n",
    "            else:\n",
    "                sent.append(vocab.get_stoi()['<unk>']) # 无，则使用<unk>的id代替\n",
    "        #print(type(sent))\n",
    "        pos = list(range(len(sent)))\n",
    "        head, tail = int(data[-1][0]), int(data[-1][-1])\n",
    "        head_p = get_pos_feature(len(sent), head)\n",
    "        tail_p = get_pos_feature(len(sent), tail)\n",
    "        sents.append(sent)\n",
    "        head_pos.append(head_p)\n",
    "        tail_pos.append(tail_p)\n",
    "    return sents, head_pos, tail_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a3e23ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sents, train_head_pos, train_tail_pos = build_data(train_raw_data, vocab)\n",
    "test_sents, test_head_pos, test_tail_pos = build_data(test_raw_data, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "fbb45f76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4,\n",
       " 22,\n",
       " 5,\n",
       " 9,\n",
       " 738,\n",
       " 319,\n",
       " 472,\n",
       " 30,\n",
       " 346,\n",
       " 240,\n",
       " 5653,\n",
       " 3654,\n",
       " 75,\n",
       " 3,\n",
       " 59,\n",
       " 483,\n",
       " 884,\n",
       " 52,\n",
       " 2,\n",
       " 52,\n",
       " 729,\n",
       " 219,\n",
       " 62,\n",
       " 966,\n",
       " 62,\n",
       " 444,\n",
       " 199,\n",
       " 391]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "5aa5d0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#将训练集和测试集的关系类别转为对应的id值\n",
    "def relation_token(relations, file):\n",
    "    relation_list = []\n",
    "    relation_dict = {}\n",
    "    out = []\n",
    "    with codecs.open(file, encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            relation_list.append(line.strip()) # 获取relaiton.txt中的关系\n",
    "        for i, rel in enumerate(relation_list):\n",
    "            relation_dict[rel] = i # 构建关系字典\n",
    "        for rel in relations:\n",
    "            out.append(relation_dict[rel]) # 获取训练或数据集中的关系转为id值\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "57630321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建关系数据\n",
    "relation_file = r'relation.txt'\n",
    "train_relation_token = relation_token(train_relation, relation_file) \n",
    "test_relation_token = relation_token(test_relation, relation_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "cbc5abf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7, 3, 2, 7, 7, 0, 0, 7, 9, 2]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_relation_token[:10] #训练集中的前10关系类别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "28b54460",
   "metadata": {},
   "outputs": [],
   "source": [
    "#将\n",
    "train_data = list(\n",
    "    zip(train_sents, train_head_pos, train_tail_pos, train_relation_token)\n",
    ")\n",
    "test_data = list(\n",
    "    zip(test_sents, test_head_pos, test_tail_pos, train_relation_token)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "55534fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "fb9085a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "dc5631e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, file):\n",
    "        super(CustomDataset, self).__init__()\n",
    "        self.file = file\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        sample = self.file[item]\n",
    "        return sample\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "4d8c3955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取训练集和测试集的dataset\n",
    "train_dataset = CustomDataset(train_data)\n",
    "test_dataset = CustomDataset(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "1c55d3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    batch.sort(key = lambda data: len(data[0]), reverse=True)\n",
    "    lens = [len(data[0]) for data in batch]\n",
    "    max_len = max(lens) # 找到一个批次中，最长的句子\n",
    "    \n",
    "    sent_list = []\n",
    "    head_pos_list = []\n",
    "    tail_pos_list = []\n",
    "    relation_list = []\n",
    "    \n",
    "    def _padding(x, max_len): # 对短句子做填充\n",
    "        return x + [0] * (max_len - len(x))\n",
    "    \n",
    "    for data in  batch:\n",
    "        sent, head_pos, tail_pos, relation = data\n",
    "        sent_list.append(_padding(sent, max_len))\n",
    "        head_pos_list.append(_padding(head_pos, max_len))\n",
    "        tail_pos_list.append(_padding(tail_pos, max_len))\n",
    "        relation_list.append(relation)\n",
    "        \n",
    "    return torch.tensor(sent_list), torch.tensor(head_pos_list), torch.tensor(tail_pos_list), torch.tensor(relation_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "fa6f1ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    "    drop_last=True, # 最后一个批次数据不足时，直接丢弃\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "1e0452f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.utils.data.dataloader.DataLoader"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "9ff284e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, word_dim, pos_size, pos_dim):\n",
    "        super(Embedding, self).__init__()\n",
    "        self.word_embed = nn.Embedding(vocab_size, word_dim, padding_idx=0)\n",
    "        self.head_pos_embed = nn.Embedding(pos_size, pos_dim, padding_idx=0)\n",
    "        self.tail_pos_embed = nn.Embedding(pos_size, pos_dim, padding_idx=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        words, head_pos, tail_pos = x\n",
    "        word_embed = self.word_embed(words)\n",
    "        head_embed = self.head_pos_embed(head_pos)\n",
    "        tail_embed = self.tail_pos_embed(tail_pos)\n",
    "        feature_embed = torch.cat([word_embed, head_embed, tail_embed], dim=-1)\n",
    "\n",
    "        return feature_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "9b3b765a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(object):\n",
    "    model_name = 'BruceCNN'\n",
    "\n",
    "    \"\"\"\n",
    "    文本处理\n",
    "    \"\"\"\n",
    "    data_path = 'data/origin'  # 原始数据\n",
    "    out_path = 'data/out'  # 数据处理的最终结果保存\n",
    "    is_chinese = True  # 是否为中文\n",
    "\n",
    "    word_segment = True  # 是否分词\n",
    "\n",
    "    relation_type = 10  # 关系种类数\n",
    "\n",
    "    min_frep = 2  # 低频词处理判断频率\n",
    "\n",
    "    \"\"\"\n",
    "    位置编码\n",
    "    \"\"\"\n",
    "    pos_limit = 50  # 【-50， 50】\n",
    "    pos_size = 102  # 2*pos_limit + 2\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Embedding层\n",
    "    \"\"\"\n",
    "    word_dim = 300  # 词向量维度\n",
    "    pos_dim = 10  # 位置向量维度\n",
    "\n",
    "    \"\"\"\n",
    "    FC层\n",
    "    \"\"\"\n",
    "    hidden_size = 100  # 隐藏层数\n",
    "    dropout = 0.5\n",
    "\n",
    "    \"\"\"\n",
    "    CNN层\n",
    "    \"\"\"\n",
    "    out_channels = 100\n",
    "    kernel_size = [3, 5]\n",
    "\n",
    "    \"\"\"\n",
    "    初始化种子\n",
    "    \"\"\"\n",
    "    seed = 1\n",
    "\n",
    "    \"\"\"\n",
    "    设置GPU\n",
    "    \"\"\"\n",
    "    use_gpu = True  # 是否使用GPU\n",
    "    gpu_id = 0  # 存在多个GPU时使用的GPU编号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "bd114660",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "ba2d084a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c8bd36",
   "metadata": {},
   "source": [
    "# PCNN关系抽取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "efb19517",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class BruceCNN(nn.Module):\n",
    "    def __init__(self, vocab_size, config):\n",
    "        super(BruceCNN, self).__init__()\n",
    "        self.model_name = 'BruceCNN'\n",
    "        self.out_channels = config.out_channels\n",
    "        self.kernel_size = config.kernel_size\n",
    "\n",
    "        self.word_dim = config.word_dim\n",
    "        self.pos_dim = config.pos_dim\n",
    "        self.pos_size = config.pos_size\n",
    "\n",
    "        self.hidden_size = config.hidden_size\n",
    "        self.dropout = config.dropout\n",
    "        self.out_dim = config.relation_type #fc层的输出维度为关系分类的数量\n",
    "\n",
    "        \"\"\"\n",
    "        isinstance(object, classinfo) 判断一个对象是否已知的类型\n",
    "        \"\"\"\n",
    "        if isinstance(self.kernel_size, int):\n",
    "            self.kernel_size = [self.kernel_size]\n",
    "        for k in self.kernel_size:\n",
    "            assert k % 2 == 1\n",
    "\n",
    "        \"\"\"\n",
    "        Embedding嵌入层\n",
    "        \"\"\"\n",
    "        self.embedding = Embedding(vocab_size, self.word_dim, self.pos_size, self.pos_dim)\n",
    "\n",
    "        self.input_dim = self.word_dim + self.pos_dim * 2  #将词向量与位置向量维度拼接后，作为卷积层的输入\n",
    "\n",
    "        \"\"\"\n",
    "        卷积层\n",
    "        \"\"\"\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Conv1d(in_channels=self.input_dim,\n",
    "                      out_channels=self.out_channels,\n",
    "                      kernel_size=k,\n",
    "                      padding=k // 2,\n",
    "                      bias=None) for k in self.kernel_size\n",
    "        ])\n",
    "\n",
    "        self.conv_dim = len(self.kernel_size) * self.out_channels #textCNN模型输出后做拼接\n",
    "\n",
    "        \"\"\"\n",
    "        fc层\n",
    "        \"\"\"\n",
    "        self.fc1 = nn.Linear(self.conv_dim, self.hidden_size)\n",
    "        self.fc2 = nn.Linear(self.hidden_size, self.out_dim)\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "\n",
    "        :param input:word_ids, headpos, tailpos, mask\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # *x, mask = input\n",
    "        x = input\n",
    "        \n",
    "        x = self.embedding(x)\n",
    "        x = torch.transpose(x, 1, 2) #将x的第一维度和第二维度互换\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        x = [F.leaky_relu(conv(x)) for conv in self.convs]  # 获取两种卷积的结果\n",
    "        x = torch.cat(x, dim=1)\n",
    "        x = F.max_pool1d(x, x.size(-1))\n",
    "        x = x.squeeze(-1)\n",
    "        #print(x)\n",
    "        #x = self.dropout(x)\n",
    "\n",
    "        x = F.leaky_relu(self.fc1(x))\n",
    "        x = F.leaky_relu(self.fc2(x))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "361a4ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "e3c483cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BruceCNN(vocab_size=vocab_size, config=config).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "11e48168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BruceCNN(\n",
      "  (embedding): Embedding(\n",
      "    (word_embed): Embedding(6618, 300, padding_idx=0)\n",
      "    (head_pos_embed): Embedding(102, 10, padding_idx=0)\n",
      "    (tail_pos_embed): Embedding(102, 10, padding_idx=0)\n",
      "  )\n",
      "  (convs): ModuleList(\n",
      "    (0): Conv1d(320, 100, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
      "    (1): Conv1d(320, 100, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
      "  )\n",
      "  (fc1): Linear(in_features=200, out_features=100, bias=True)\n",
      "  (fc2): Linear(in_features=100, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "2288c338",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import lr_scheduler\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "95356783",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "470f3898",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, device, data_loader, model, optimizer, loss_fn):\n",
    "    model.train()\n",
    "    total_loss = []\n",
    "    \n",
    "    for batch_idx, batch in enumerate(data_loader):\n",
    "        *x, y = [data.to(device) for data in batch]\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss.append(loss)\n",
    "        \n",
    "        # 记录日志\n",
    "        data_cal = len(data_loader.dataset) if batch_idx == len(data_loader) else batch_idx * len(y)\n",
    "        \n",
    "        if(batch_idx % 10 == 0) or batch_idx == len(data_loader):\n",
    "            print('Training epoch:{} [{} / {} ({:.0f}%)] \\t Loss:{:.6f}'.format(epoch, \n",
    "                                                                                 data_cal, \n",
    "                                                                                 len(data_loader.dataset), \n",
    "                                                                                 100.*batch_idx / len(data_loader), \n",
    "                                                                                 loss.item()))\n",
    "    #print('************************epoch结束********************************')       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "0fd40f33",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def validate(data_loader, model, device,):\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        total_y_true = np.empty(0)\n",
    "        total_y_pred = np.empty(0)\n",
    "        \n",
    "        for batch_idx, batch in enumerate(data_loader):\n",
    "            *x, y = [data.to(device) for data in batch]\n",
    "            y_pred = model(x)\n",
    "            y_pred = y_pred.argmax(dim = -1)\n",
    "            \n",
    "            try:\n",
    "                y, y_pred = y.numpy(), y_pred.numpy()\n",
    "            except:\n",
    "                y, y_pred = y.cpu().numpy(), y_pred.cpu().numpy()\n",
    "            \n",
    "            total_y_true = np.append(total_y_true, y)\n",
    "            total_y_pred = np.append(total_y_pred, y_pred)\n",
    "         \n",
    "        total_f1 = []\n",
    "        \n",
    "        for average in ['macro', 'micro']:\n",
    "            precision, recall, f1, _ = precision_recall_fscore_support(total_y_true, total_y_pred, average=average)\n",
    "            \n",
    "            print(f'{average} metrics: [precision: {precision: .4f}, recall: {recall: .4f}, f1: {f1: .4f}]')\n",
    "            \n",
    "            total_f1.append(f1)\n",
    "        print('*************************epoch结束************************************')    \n",
    "    return total_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "41a62318",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch:1 [0 / 4000 (0%)] \t Loss:2.344216\n",
      "Training epoch:1 [1280 / 4000 (32%)] \t Loss:24.179258\n",
      "Training epoch:1 [2560 / 4000 (65%)] \t Loss:20.385035\n",
      "Training epoch:1 [3840 / 4000 (97%)] \t Loss:44.534355\n",
      "macro metrics: [precision:  0.0395, recall:  0.0979, f1:  0.0284]\n",
      "micro metrics: [precision:  0.1417, recall:  0.1417, f1:  0.1417]\n",
      "*************************epoch结束************************************\n",
      "Training epoch:2 [0 / 4000 (0%)] \t Loss:21.287914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\miniconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch:2 [1280 / 4000 (32%)] \t Loss:4.668078\n",
      "Training epoch:2 [2560 / 4000 (65%)] \t Loss:13.757561\n",
      "Training epoch:2 [3840 / 4000 (97%)] \t Loss:2.308952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\miniconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "macro metrics: [precision:  0.0404, recall:  0.1042, f1:  0.0108]\n",
      "micro metrics: [precision:  0.0234, recall:  0.0234, f1:  0.0234]\n",
      "*************************epoch结束************************************\n",
      "Training epoch:3 [0 / 4000 (0%)] \t Loss:2.279138\n",
      "Training epoch:3 [1280 / 4000 (32%)] \t Loss:2.302521\n",
      "Training epoch:3 [2560 / 4000 (65%)] \t Loss:2.769456\n",
      "Training epoch:3 [3840 / 4000 (97%)] \t Loss:2.334203\n",
      "macro metrics: [precision:  0.0616, recall:  0.1051, f1:  0.0117]\n",
      "micro metrics: [precision:  0.0212, recall:  0.0212, f1:  0.0212]\n",
      "*************************epoch结束************************************\n",
      "Training epoch:4 [0 / 4000 (0%)] \t Loss:2.332601\n",
      "Training epoch:4 [1280 / 4000 (32%)] \t Loss:2.258194\n",
      "Training epoch:4 [2560 / 4000 (65%)] \t Loss:1.990674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\miniconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch:4 [3840 / 4000 (97%)] \t Loss:2.274114\n",
      "macro metrics: [precision:  0.0504, recall:  0.0871, f1:  0.0317]\n",
      "micro metrics: [precision:  0.1116, recall:  0.1116, f1:  0.1116]\n",
      "*************************epoch结束************************************\n",
      "Training epoch:5 [0 / 4000 (0%)] \t Loss:13.392697\n",
      "Training epoch:5 [1280 / 4000 (32%)] \t Loss:2.971462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\miniconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch:5 [2560 / 4000 (65%)] \t Loss:4.288446\n",
      "Training epoch:5 [3840 / 4000 (97%)] \t Loss:2.617610\n",
      "macro metrics: [precision:  0.1252, recall:  0.1032, f1:  0.0266]\n",
      "micro metrics: [precision:  0.0279, recall:  0.0279, f1:  0.0279]\n",
      "*************************epoch结束************************************\n",
      "Training epoch:6 [0 / 4000 (0%)] \t Loss:2.619158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\miniconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch:6 [1280 / 4000 (32%)] \t Loss:2.359405\n",
      "Training epoch:6 [2560 / 4000 (65%)] \t Loss:3.595909\n",
      "Training epoch:6 [3840 / 4000 (97%)] \t Loss:2.481293\n",
      "macro metrics: [precision:  0.0501, recall:  0.0983, f1:  0.0080]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\miniconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro metrics: [precision:  0.0167, recall:  0.0167, f1:  0.0167]\n",
      "*************************epoch结束************************************\n",
      "Training epoch:7 [0 / 4000 (0%)] \t Loss:2.280453\n",
      "Training epoch:7 [1280 / 4000 (32%)] \t Loss:2.109293\n",
      "Training epoch:7 [2560 / 4000 (65%)] \t Loss:2.234241\n",
      "Training epoch:7 [3840 / 4000 (97%)] \t Loss:8.671333\n",
      "macro metrics: [precision:  0.1001, recall:  0.1051, f1:  0.0215]\n",
      "micro metrics: [precision:  0.0324, recall:  0.0324, f1:  0.0324]\n",
      "*************************epoch结束************************************\n",
      "Training epoch:8 [0 / 4000 (0%)] \t Loss:3.106563\n",
      "Training epoch:8 [1280 / 4000 (32%)] \t Loss:4.561539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\miniconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch:8 [2560 / 4000 (65%)] \t Loss:4.721201\n",
      "Training epoch:8 [3840 / 4000 (97%)] \t Loss:1.867968\n",
      "macro metrics: [precision:  0.1480, recall:  0.0872, f1:  0.0372]\n",
      "micro metrics: [precision:  0.0725, recall:  0.0725, f1:  0.0725]\n",
      "*************************epoch结束************************************\n",
      "Training epoch:9 [0 / 4000 (0%)] \t Loss:2.802621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\miniconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch:9 [1280 / 4000 (32%)] \t Loss:3.039879\n",
      "Training epoch:9 [2560 / 4000 (65%)] \t Loss:7.719632\n",
      "Training epoch:9 [3840 / 4000 (97%)] \t Loss:2.380845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\miniconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "macro metrics: [precision:  0.0562, recall:  0.0967, f1:  0.0096]\n",
      "micro metrics: [precision:  0.0179, recall:  0.0179, f1:  0.0179]\n",
      "*************************epoch结束************************************\n",
      "Training epoch:10 [0 / 4000 (0%)] \t Loss:2.045395\n",
      "Training epoch:10 [1280 / 4000 (32%)] \t Loss:10.711118\n",
      "Training epoch:10 [2560 / 4000 (65%)] \t Loss:2.047909\n",
      "Training epoch:10 [3840 / 4000 (97%)] \t Loss:2.115601\n",
      "macro metrics: [precision:  0.0860, recall:  0.1009, f1:  0.0108]\n",
      "micro metrics: [precision:  0.0190, recall:  0.0190, f1:  0.0190]\n",
      "*************************epoch结束************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\miniconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 11):\n",
    "    train(epoch, device, train_dataloader, model, optimizer, loss_fn)\n",
    "    macro_f1, micro_f1 = validate(test_dataloader, model, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3c15da",
   "metadata": {},
   "source": [
    "# 用GRU的关系抽取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "5fac64e0",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#\n",
    "class GRU(nn.Module):\n",
    "    def __init__(self, vocab_size, config):\n",
    "        super(GRU, self).__init__()\n",
    "        self.model_name = 'GRU'\n",
    "        self.word_dim = config.word_dim\n",
    "        self.pos_size = config.pos_size\n",
    "        self.pos_dim = config.pos_dim\n",
    "        self.lstm_layers = 2\n",
    "        self.hidden_size = config.hidden_size\n",
    "        self.dropout = config.dropout\n",
    "        self.out_dim= config.relation_type\n",
    "        \n",
    "        self.embedding = Embedding(vocab_size, self.word_dim, self.pos_size, self.pos_dim)\n",
    "        \n",
    "        self.input_dim = self.word_dim + self.pos_dim * 2\n",
    "        \n",
    "        self.gru = nn.GRU(\n",
    "            input_size = self.input_dim,\n",
    "            hidden_size = self.hidden_size,\n",
    "            num_layers = self.lstm_layers,\n",
    "            dropout = self.dropout,\n",
    "            bidirectional = True,\n",
    "            bias = True,\n",
    "            batch_first = True\n",
    "        )\n",
    "        \n",
    "        linear_input_dim = self.hidden_size\n",
    "        self.fc1 = nn.Linear(linear_input_dim, self.hidden_size)\n",
    "        self.fc2 = nn.Linear(self.hidden_size, self.out_dim)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        x= input\n",
    "        x = self.embedding(x)\n",
    "        out_put, h_n = self.gru(x)\n",
    "        h_n = h_n[-1,:,:]\n",
    "        y = F.leaky_relu(self.fc1(h_n))\n",
    "        out = F.leaky_relu(self.fc2(y))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "a167ee27",
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_model = GRU(vocab_size, config).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "4dd48cf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GRU(\n",
       "  (embedding): Embedding(\n",
       "    (word_embed): Embedding(6618, 300, padding_idx=0)\n",
       "    (head_pos_embed): Embedding(102, 10, padding_idx=0)\n",
       "    (tail_pos_embed): Embedding(102, 10, padding_idx=0)\n",
       "  )\n",
       "  (gru): GRU(320, 100, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
       "  (fc1): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (fc2): Linear(in_features=100, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gru_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "8db1a4a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch:1 [0 / 4000 (0%)] \t Loss:2.300079\n",
      "Training epoch:1 [1280 / 4000 (32%)] \t Loss:2.294780\n",
      "Training epoch:1 [2560 / 4000 (65%)] \t Loss:2.302145\n",
      "Training epoch:1 [3840 / 4000 (97%)] \t Loss:2.300515\n",
      "macro metrics: [precision:  0.0323, recall:  0.0988, f1:  0.0438]\n",
      "micro metrics: [precision:  0.1094, recall:  0.1094, f1:  0.1094]\n",
      "*************************epoch结束************************************\n",
      "Training epoch:2 [0 / 4000 (0%)] \t Loss:2.298873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\miniconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch:2 [1280 / 4000 (32%)] \t Loss:2.299347\n",
      "Training epoch:2 [2560 / 4000 (65%)] \t Loss:2.302216\n",
      "Training epoch:2 [3840 / 4000 (97%)] \t Loss:2.296124\n",
      "macro metrics: [precision:  0.0394, recall:  0.1001, f1:  0.0485]\n",
      "micro metrics: [precision:  0.1194, recall:  0.1194, f1:  0.1194]\n",
      "*************************epoch结束************************************\n",
      "Training epoch:3 [0 / 4000 (0%)] \t Loss:2.292578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\miniconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch:3 [1280 / 4000 (32%)] \t Loss:2.295928\n",
      "Training epoch:3 [2560 / 4000 (65%)] \t Loss:2.301129\n",
      "Training epoch:3 [3840 / 4000 (97%)] \t Loss:2.299601\n",
      "macro metrics: [precision:  0.0327, recall:  0.0997, f1:  0.0455]\n",
      "micro metrics: [precision:  0.1150, recall:  0.1150, f1:  0.1150]\n",
      "*************************epoch结束************************************\n",
      "Training epoch:4 [0 / 4000 (0%)] \t Loss:2.302959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\miniconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch:4 [1280 / 4000 (32%)] \t Loss:2.301828\n",
      "Training epoch:4 [2560 / 4000 (65%)] \t Loss:2.301876\n",
      "Training epoch:4 [3840 / 4000 (97%)] \t Loss:2.298701\n",
      "macro metrics: [precision:  0.0348, recall:  0.0960, f1:  0.0442]\n",
      "micro metrics: [precision:  0.1060, recall:  0.1060, f1:  0.1060]\n",
      "*************************epoch结束************************************\n",
      "Training epoch:5 [0 / 4000 (0%)] \t Loss:2.302525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\miniconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch:5 [1280 / 4000 (32%)] \t Loss:2.298335\n",
      "Training epoch:5 [2560 / 4000 (65%)] \t Loss:2.306630\n",
      "Training epoch:5 [3840 / 4000 (97%)] \t Loss:2.301935\n",
      "macro metrics: [precision:  0.0383, recall:  0.1017, f1:  0.0471]\n",
      "micro metrics: [precision:  0.1105, recall:  0.1105, f1:  0.1105]\n",
      "*************************epoch结束************************************\n",
      "Training epoch:6 [0 / 4000 (0%)] \t Loss:2.297587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\miniconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch:6 [1280 / 4000 (32%)] \t Loss:2.304281\n",
      "Training epoch:6 [2560 / 4000 (65%)] \t Loss:2.302261\n",
      "Training epoch:6 [3840 / 4000 (97%)] \t Loss:2.297109\n",
      "macro metrics: [precision:  0.0312, recall:  0.0944, f1:  0.0425]\n",
      "micro metrics: [precision:  0.1138, recall:  0.1138, f1:  0.1138]\n",
      "*************************epoch结束************************************\n",
      "Training epoch:7 [0 / 4000 (0%)] \t Loss:2.293720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\miniconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch:7 [1280 / 4000 (32%)] \t Loss:2.299947\n",
      "Training epoch:7 [2560 / 4000 (65%)] \t Loss:2.301314\n",
      "Training epoch:7 [3840 / 4000 (97%)] \t Loss:2.309107\n",
      "macro metrics: [precision:  0.0384, recall:  0.1007, f1:  0.0473]\n",
      "micro metrics: [precision:  0.1150, recall:  0.1150, f1:  0.1150]\n",
      "*************************epoch结束************************************\n",
      "Training epoch:8 [0 / 4000 (0%)] \t Loss:2.309464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\miniconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch:8 [1280 / 4000 (32%)] \t Loss:2.297115\n",
      "Training epoch:8 [2560 / 4000 (65%)] \t Loss:2.293951\n",
      "Training epoch:8 [3840 / 4000 (97%)] \t Loss:2.303624\n",
      "macro metrics: [precision:  0.0388, recall:  0.1006, f1:  0.0482]\n",
      "micro metrics: [precision:  0.1172, recall:  0.1172, f1:  0.1172]\n",
      "*************************epoch结束************************************\n",
      "Training epoch:9 [0 / 4000 (0%)] \t Loss:2.313095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\miniconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch:9 [1280 / 4000 (32%)] \t Loss:2.310285\n",
      "Training epoch:9 [2560 / 4000 (65%)] \t Loss:2.299006\n",
      "Training epoch:9 [3840 / 4000 (97%)] \t Loss:2.305078\n",
      "macro metrics: [precision:  0.0319, recall:  0.0958, f1:  0.0443]\n",
      "micro metrics: [precision:  0.1116, recall:  0.1116, f1:  0.1116]\n",
      "*************************epoch结束************************************\n",
      "Training epoch:10 [0 / 4000 (0%)] \t Loss:2.296948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\miniconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch:10 [1280 / 4000 (32%)] \t Loss:2.299944\n",
      "Training epoch:10 [2560 / 4000 (65%)] \t Loss:2.301326\n",
      "Training epoch:10 [3840 / 4000 (97%)] \t Loss:2.300161\n",
      "macro metrics: [precision:  0.0380, recall:  0.1007, f1:  0.0473]\n",
      "micro metrics: [precision:  0.1150, recall:  0.1150, f1:  0.1150]\n",
      "*************************epoch结束************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\miniconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 11):\n",
    "    train(epoch, device, train_dataloader, bilstm_model, optimizer, loss_fn)\n",
    "    macro_f1, micro_f1 = validate(test_dataloader, bilstm_model, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd939910",
   "metadata": {},
   "source": [
    "# GRU+注意力机制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "69aca3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义注意力机制\n",
    "class Attn(nn.Module):\n",
    "    def __init__(self, method, hidden_size):\n",
    "        super(Attn, self).__init__()\n",
    "        \n",
    "        self.method = method\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        \n",
    "        if self.method == 'general':\n",
    "            self.attn = nn.Linear(self.hidden_size, hidden_size)\n",
    "            \n",
    "        elif self.method == 'concat':\n",
    "            self.attn = nn.Linear(self.hidden_size * 2, hidden_size)\n",
    "            self.v = nn.Parameter(torch.FloatTensor(1, hidden_size))\n",
    "    \n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        max_len = encoder_outputs.size(0)\n",
    "        batch_size = encoder_outputs.size(1)\n",
    "            \n",
    "        attn_energies = torch.zeros(batch_size, max_len)\n",
    "        attn_energies = attn_energies.to(device)\n",
    "        \n",
    "        for n in range(batch_size):\n",
    "            for i in range(max_len):\n",
    "                attn_energies[b, i] = self.score(hidden[: b], encoder_outputs[i, b].unsqueeze(0))\n",
    "        return F.softmax(attn_energies, dim=1).unsqueeze(1)\n",
    "    \n",
    "    # 定义注意力打分函数\n",
    "    def score(self, hidden, encoder_output):\n",
    "        if self.method == 'dot':\n",
    "            energy = hidden.squeeze(0).dot(encoder_output.squeeze(0))\n",
    "            return energy\n",
    "        \n",
    "        elif self.method == 'general':\n",
    "            energy = self.attn(encoder_output)\n",
    "            energy = hidden.squeeze(0).dot(energy.squeeze(0))\n",
    "            return energy\n",
    "        \n",
    "        elif self.method == 'concat':\n",
    "            energy = self.attn(torch.cat(hidden, encoder_output), 1)\n",
    "            energy = self.v.squeeze(0).dot(energy.squeeze(0))\n",
    "            return energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "9daf00ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnGRU(nn.Module):\n",
    "    def __init__(self, attn_model, embedding, hidden_size, output_size, n_layers = 1, dropout = 0.1):\n",
    "        super(AttnGRU, self).__init__()\n",
    "        \n",
    "        # 定义参数\n",
    "        self.attn_model = attn_model\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        # 定义层\n",
    "        self.embedding = embedding\n",
    "        self.embedding_drop = nn.Dropout(dropout)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout = (0 if n_layers == 1 else dropout))\n",
    "        self.concat = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "        # 选择注意力机制\n",
    "        if attn_model != 'none':\n",
    "            self.attn = Attn(attn_model, hidden_size)\n",
    "    \n",
    "    def forward(self, input_seq, last_hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input_seq)\n",
    "        embedded = self.embedding_drop(embedded)\n",
    "        # if(embedded.size(0) != 1):\n",
    "        #    raiseValueError('Decoder input sequence length should be 1')\n",
    "        rnn_output, hidden = self.gru(embedded, last_hidden) # 经过bilstm层\n",
    "        \n",
    "        attn_weights = self.attn(rnn_output, encoder_outputs)\n",
    "        context = attn_weights.bmm(encoder_outputs.transpose(0, 1))\n",
    "        \n",
    "        # 注意力向量使用隐藏层状态和context向量\n",
    "        rnn_output = rnn_output.squeeze(0)\n",
    "        context = context.squeeze(1)\n",
    "        concat_input = torch.cat((rnn_output, context), 1)\n",
    "        concat_output = torch.tan(self.concat(concat_input))\n",
    "        output = self.out(concat_output)\n",
    "        \n",
    "        return output, hidden, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "7ae09921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Attn()"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_model = Attn('dot', 100)\n",
    "attn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "9665d112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(\n",
       "  (word_embed): Embedding(6618, 300, padding_idx=0)\n",
       "  (head_pos_embed): Embedding(102, 10, padding_idx=0)\n",
       "  (tail_pos_embed): Embedding(102, 10, padding_idx=0)\n",
       ")"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding = Embedding(vocab_size, config.word_dim, config.pos_size, config.pos_dim)\n",
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "70f62056",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AttnGRU(\n",
       "  (attn_model): Attn()\n",
       "  (embedding): Embedding(\n",
       "    (word_embed): Embedding(6618, 300, padding_idx=0)\n",
       "    (head_pos_embed): Embedding(102, 10, padding_idx=0)\n",
       "    (tail_pos_embed): Embedding(102, 10, padding_idx=0)\n",
       "  )\n",
       "  (embedding_drop): Dropout(p=0.1, inplace=False)\n",
       "  (gru): GRU(100, 100)\n",
       "  (concat): Linear(in_features=200, out_features=100, bias=True)\n",
       "  (out): Linear(in_features=100, out_features=10, bias=True)\n",
       "  (attn): Attn(\n",
       "    (method): Attn()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attnGru = AttnGRU(attn_model, embedding, config.hidden_size, config.relation_type)\n",
    "attnGru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "666c1961",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "forward() missing 2 required positional arguments: 'last_hidden' and 'encoder_outputs'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [182]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m11\u001b[39m):\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattnGru\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m     macro_f1, micro_f1 \u001b[38;5;241m=\u001b[39m validate(test_dataloader, attnGru, device)\n",
      "Input \u001b[1;32mIn [146]\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(epoch, device, data_loader, model, optimizer, loss_fn)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;241m*\u001b[39mx, y \u001b[38;5;241m=\u001b[39m [data\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m batch]\n\u001b[0;32m      7\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m----> 8\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(y_pred, y)\n\u001b[0;32m     10\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mD:\\miniconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "\u001b[1;31mTypeError\u001b[0m: forward() missing 2 required positional arguments: 'last_hidden' and 'encoder_outputs'"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 11):\n",
    "    train(epoch, device, train_dataloader, attnGru, optimizer, loss_fn)\n",
    "    macro_f1, micro_f1 = validate(test_dataloader, attnGru, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7190094c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
